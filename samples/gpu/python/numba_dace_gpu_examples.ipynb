{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611d7d6f-c569-4111-b2ed-61784a89ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, cuda\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8aa299-6b32-4820-a075-f06e910ee2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100000000\n",
    "a = np.ones(n, dtype = np.float64)\n",
    "a.nbytes/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f4de62-1797-4efa-bd05-482af88ed78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal function to run on cpu\n",
    "def func(x):\n",
    "    a=x.copy()\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i]+= 1\n",
    "    return a\n",
    "\n",
    "# function optimized to run on gpu \n",
    "@jit(target_backend='cuda')\n",
    "def func_numba_cuda(x):\n",
    "    a=x.copy()\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i]+= 1\n",
    "    return a\n",
    "\n",
    "@jit \n",
    "def func_numba(x):\n",
    "    a=x.copy()\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i]+= 1\n",
    "    return a\n",
    "\n",
    "@jit \n",
    "def func_numba_nonvecable(x):\n",
    "    a=x.copy()\n",
    "    asum=0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i]+= 1\n",
    "        asum += a[i]\n",
    "    return asum\n",
    "\n",
    "def func_nonvecable(x):\n",
    "    a=x.copy()\n",
    "    asum=0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i]+= 1\n",
    "        asum += a[i]\n",
    "    return asum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02de604-0fec-4f7e-8b1c-4dd059ea6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:                  21.7702771241311  result=  200000000.0\n",
      "numpy:                  21.51454497780651  result=  200000000.0\n",
      "numpy nonvecable:        35.72810862399638  result=  200000000.0\n",
      "numpy nonvecable:        34.885415617143735  result=  200000000.0\n",
      "numba jit nonvecable:    0.6842681178823113  result=  200000000.0\n",
      "numba jit nonvecable:    0.21199987595900893  result=  200000000.0\n",
      "numba jit:               0.2455444810912013  result=  200000000.0\n",
      "numba jit:               0.15868577198125422  result=  200000000.0\n",
      "numba jit:               0.16060847020708025  result=  200000000.0\n",
      "numba jit backend cuda:  0.24505614885129035  result=  200000000.0\n",
      "numba jit backend cuda:  0.1603886450175196  result=  200000000.0\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "b=func(a)\n",
    "print(\"numpy:                 \", timer()-start, \" result= \",b.sum()) \n",
    "start = timer()\n",
    "b=func(a)\n",
    "print(\"numpy:                 \", timer()-start, \" result= \",b.sum()) \n",
    "\n",
    "start = timer()\n",
    "b=func_nonvecable(a)\n",
    "print(\"numpy nonvecable:       \", timer()-start, \" result= \",b)\n",
    "start = timer()\n",
    "b=func_nonvecable(a)\n",
    "print(\"numpy nonvecable:       \", timer()-start, \" result= \",b)\n",
    "\n",
    "start = timer()\n",
    "b=func_numba_nonvecable(a)\n",
    "print(\"numba jit nonvecable:   \", timer()-start, \" result= \",b)\n",
    "start = timer()\n",
    "b=func_numba_nonvecable(a)\n",
    "print(\"numba jit nonvecable:   \", timer()-start, \" result= \",b)\n",
    "\n",
    "start = timer()\n",
    "b=func_numba(a)\n",
    "print(\"numba jit:              \", timer()-start, \" result= \",b.sum())\n",
    "start = timer()\n",
    "b=func_numba(a)\n",
    "print(\"numba jit:              \", timer()-start, \" result= \",b.sum())\n",
    "start = timer()\n",
    "b=func_numba(a)\n",
    "print(\"numba jit:              \", timer()-start, \" result= \",b.sum())\n",
    "   \n",
    "start = timer()\n",
    "b=func_numba_cuda(a)\n",
    "print(\"numba jit backend cuda: \", timer()-start, \" result= \",b.sum())\n",
    "start = timer()\n",
    "b=func_numba_cuda(a)\n",
    "print(\"numba jit backend cuda: \", timer()-start, \" result= \",b.sum())\n",
    "\n",
    "#None of the above seem to utilize GPU as evidenced by nvidia-smi\n",
    "#The jit ones need a warmup (perhaps to compile)\n",
    "#numpy:                  21.35097421798855  result=  200000000.0\n",
    "#numpy:                  20.661394510883838  result=  200000000.0\n",
    "#numpy nonvecable:        35.62613185006194  result=  200000000.0\n",
    "#numpy nonvecable:        35.486699688015506  result=  200000000.0\n",
    "#numba jit nonvecable:    0.6851420938037336  result=  200000000.0\n",
    "#numba jit nonvecable:    0.21572539093904197  result=  200000000.0\n",
    "#numba jit:               0.2543515469878912  result=  200000000.0\n",
    "#numba jit:               0.16620380710810423  result=  200000000.0\n",
    "#numba jit:               0.16279309103265405  result=  200000000.0\n",
    "#numba jit backend cuda:  0.25583608797751367  result=  200000000.0\n",
    "#numba jit backend cuda:  0.17059857910498977  result=  200000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2457c2b2-f698-458e-959d-fe70bdb98a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" rel=\"stylesheet\"><script src=\"https://spcl.github.io/dace/webclient2/dist/sdfv.js\"></script>\n",
       "<link href=\"https://spcl.github.io/dace/webclient2/sdfv.css\" rel=\"stylesheet\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dace:                1.4020556551404297  result=  200000000.0\n",
      "dace:                0.22581780282780528  result=  200000000.0\n",
      "dace:                0.23822007817216218  result=  200000000.0\n"
     ]
    }
   ],
   "source": [
    "import dace\n",
    "dace_func = dace.program(auto_optimize=True)(func)\n",
    "\n",
    "start = timer()\n",
    "b=dace_func(a)\n",
    "print(\"dace:               \", timer()-start, \" result= \",b.sum())\n",
    "start = timer()\n",
    "b=dace_func(a)\n",
    "print(\"dace:               \", timer()-start, \" result= \",b.sum())\n",
    "start = timer()\n",
    "b=dace_func(a)\n",
    "print(\"dace:               \", timer()-start, \" result= \",b.sum())\n",
    "#dace:                1.3049751319922507  result=  200000000.0\n",
    "#dace:                0.22182884812355042  result=  200000000.0\n",
    "#dace:                0.21486610011197627  result=  200000000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad78508-9354-4d94-ae60-0b013b0710f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba cuda jit:      0.33763771899975836  result= \n",
      "numba cuda jit:      0.000697998097166419  result= \n",
      "numba cuda jit:      0.00012038717977702618  result= \n",
      "numba cuda jit:      0.00010664109140634537  result= \n"
     ]
    }
   ],
   "source": [
    "#This seems to utilize GPU,\n",
    "# the python process appears in nvidiai-smi\n",
    "# the memory usage on device 0 increases by 800MiB everytime the cell runs!\n",
    "#Before run | N/A   31C    P0              28W / 250W |    125MiB / 32768MiB |      0%      Default |\n",
    "#After  run | N/A   31C    P0              38W / 250W |   1201MiB / 32768MiB |      0%      Default |\n",
    "# How to clean it up?\n",
    "#\n",
    "#Also, it needs warmup runs\n",
    "\n",
    "@cuda.jit\n",
    "def func_numba_cuda_jit(a):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos < a.size: # Check array boundaries\n",
    "        a[pos]+= 1\n",
    "    #return a\n",
    "\n",
    "d_a = cuda.to_device(a) # upload a to the GPU\n",
    "threadsperblock = 256\n",
    "blockspergrid = (d_a.size + (threadsperblock - 1)) // threadsperblock\n",
    "\n",
    "start = timer()\n",
    "func_numba_cuda_jit[blockspergrid, threadsperblock](d_a)\n",
    "print(\"numba cuda jit:     \", timer()-start, \" result= \")\n",
    "start = timer()\n",
    "func_numba_cuda_jit[blockspergrid, threadsperblock](d_a)\n",
    "print(\"numba cuda jit:     \", timer()-start, \" result= \")\n",
    "start = timer()\n",
    "func_numba_cuda_jit[blockspergrid, threadsperblock](d_a)\n",
    "print(\"numba cuda jit:     \", timer()-start, \" result= \")\n",
    "start = timer()\n",
    "func_numba_cuda_jit[blockspergrid, threadsperblock](d_a)\n",
    "print(\"numba cuda jit:     \", timer()-start, \" result= \")\n",
    "\n",
    "#numba cuda jit:      0.2099861961323768  result= \n",
    "#numba cuda jit:      0.00035113305784761906  result= \n",
    "#numba cuda jit:      9.70128457993269e-05  result= \n",
    "#numba cuda jit:      9.366683661937714e-05  result= \n",
    "#numba cuda jit:      0.2675072008278221  result= \n",
    "#numba cuda jit:      0.000666347099468112  result= \n",
    "#numba cuda jit:      0.0001106590498238802  result= \n",
    "#numba cuda jit:      9.953812696039677e-05  result= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f882200-0f7e-4b79-bebd-16e6838a9108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "def go_slow(a):\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i] += 1\n",
    "    return a\n",
    "\n",
    "@jit\n",
    "def go_fast(a):\n",
    "    for i in range(a.shape[0]):\n",
    "        a[i] += 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a52cd9-85c1-4051-a6ec-d4569cb9798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow: 41971.45ms fast: 87.89ms speedup: 477.6x\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "# jit warmup\n",
    "go_fast(a)\n",
    "go_slow(a)\n",
    "\n",
    "ts = timeit(lambda: go_slow(a), number=2)\n",
    "tf = timeit(lambda: go_fast(a), number=2)\n",
    "print(f'slow: {ts*1000:.2f}ms fast: {tf*1000:.2f}ms speedup: {ts/tf:.1f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92d837c-0ea9-48fc-9e1c-d7ed623c2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def increment_by_one(a):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos < a.size:  # Check array boundaries\n",
    "        a[pos] += 1\n",
    "\n",
    "d_a = cuda.to_device(a) # upload a to the GPU\n",
    "threadsperblock = 256\n",
    "blockspergrid = (d_a.size + (threadsperblock - 1)) // threadsperblock\n",
    "increment_by_one[blockspergrid, threadsperblock](d_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e400e7d-0329-4578-87ba-b2d30b8c0b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow: 42651.39ms fast: 87.54ms speedup: 487.2x\n",
      "fast: 87.54ms cuda: 0.86ms speedup: 102.3x\n",
      "slow: 42651.39ms cuda: 0.86ms speedup: 49854.6x\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "# warmup\n",
    "go_fast(a)\n",
    "go_slow(a)\n",
    "increment_by_one[blockspergrid, threadsperblock](d_a)\n",
    "\n",
    "tf = timeit(lambda: go_fast(a), number=2)\n",
    "ts = timeit(lambda: go_slow(a), number=2)\n",
    "tg = timeit(lambda: increment_by_one[blockspergrid, threadsperblock](d_a),\n",
    "    number=2)\n",
    "\n",
    "print(f'slow: {ts*1000:.2f}ms fast: {tf*1000:.2f}ms speedup: {ts/tf:.1f}x')\n",
    "print(f'fast: {tf*1000:.2f}ms cuda: {tg*1000:.2f}ms speedup: {tf/tg:.1f}x')\n",
    "print(f'slow: {ts*1000:.2f}ms cuda: {tg*1000:.2f}ms speedup: {ts/tg:.1f}x')\n",
    "#slow: 42823.86ms fast: 86.61ms speedup: 494.5x\n",
    "#fast: 86.61ms cuda: 0.78ms speedup: 110.5x\n",
    "#slow: 42823.86ms cuda: 0.78ms speedup: 54619.5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "302e942b-b893-4d8d-b72b-6ecdb7855577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event timing: 2.098ms\n"
     ]
    }
   ],
   "source": [
    "start = cuda.event()\n",
    "end = cuda.event()\n",
    "start.record()\n",
    "increment_by_one[blockspergrid, threadsperblock](d_a)\n",
    "end.record()\n",
    "end.synchronize()\n",
    "elapsed = start.elapsed_time(end)\n",
    "print(f'Event timing: {elapsed:.3f}ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d2bb5d-32a6-4f94-bacf-d39487d681b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast: 87.54ms cuda: 4.22ms speedup: 20.8x\n"
     ]
    }
   ],
   "source": [
    "def inc(blockspergrid, threadsperblock, a):\n",
    "    increment_by_one[blockspergrid, threadsperblock](a)\n",
    "    cuda.synchronize()\n",
    "\n",
    "tg = timeit(lambda: inc(blockspergrid, threadsperblock, d_a), number=2)\n",
    "print(f'fast: {tf*1000:.2f}ms cuda: {tg*1000:.2f}ms speedup: {tf/tg:.1f}x')\n",
    "#fast: 86.61ms cuda: 4.12ms speedup: 21.0x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc15823-4134-4108-9013-0e7cd4e62e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
