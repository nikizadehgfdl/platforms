{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e92eef7",
   "metadata": {},
   "source": [
    "# GPU offloading in Fortran\n",
    "This notebook guides through a few test programs to try and study gpu offloading in Fortran. \n",
    "\n",
    "The main routine we explore, benchmark2d2, consists of a 2d array update (4-point averaging):\n",
    "```\n",
    "  iter=0\n",
    "  do while (iter < iter_max)\n",
    "    do j=1,n-2;do i=1,m-2\n",
    "      AN(i,j) = 0.25*(A(i-1,j)+A(i+1,j)+A(i,j-1)+A(i,j+1))\n",
    "    enddo; enddo\n",
    "    do j=1,n-2;do i=1,m-2\n",
    "      A(i,j) = AN(i,j)\n",
    "    enddo; enddo\n",
    "    iter = iter+1\n",
    "  enddo\n",
    "```\n",
    "The runtime is proportional to the size of the array (m\\*n) as well as the number of iterations (iter_max).   \n",
    "\n",
    "We also explore the timings of a simpler, embarassingly parallel array update:\n",
    "```\n",
    "do j=0,n-1;do i=0,m-1\n",
    "     iter=0\n",
    "     do while (iter < iter_max)\n",
    "        A(i,j) = A(i,j)*(A(i,j)-1.0)\n",
    "        iter = iter+1\n",
    "     enddo\n",
    "enddo; enddo\n",
    "```\n",
    "\n",
    "We realize that usually such  embarassingly parallel workload does not represent the ones that arise in science and engineering. It was designed only as a starting point to try various offloading schemes and compare their potential utility in Fortran.\n",
    "\n",
    "\n",
    "## Executive Summary\n",
    "- Offload via Fortran \"do concurrent\" scheme seems to be on par with  openACC \"manged mode\"  in speed.\n",
    "- Offload via openMP \"target\"              scheme seems to be on par with  openACC \"non-manged mode\" in speed.\n",
    "- Both of these schemes are available and were tested in nvfortran for Nvidia GPUs and ifx for Intel GPUs. \n",
    "- However the cross-compatibility (using ifx to offload to Nvidia Or using nvfortran to offload to Intel device) was not tested. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d34522",
   "metadata": {},
   "source": [
    "### Simple array test on gfdl gpubox\n",
    "\n",
    "#### The bad\n",
    "- For the more complex problem the GPU answers (final_sum) are not repeatable and are also too different from CPU answers! Why?\n",
    "\n",
    "#### The good\n",
    "- For the simpler problem the GPU and CPU answers are the same.\n",
    "- 'do concurrent' is much fater than openmp offload, partularly for larger problems. Why?\n",
    "- Note the 4000x speedup on GPU relative to single thread CPU for a fully vectorizable subroutine. Ain't that weird?\n",
    "- The GPU/CPU speedup reduces to 15x for a more realistic subroutien like 4-point average (Laplace operator).\n",
    "- Timing to solution scales linearly with problem size for 'do concurrent' but lags behind for openmp. Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11639e",
   "metadata": {},
   "source": [
    "### Gotchas\n",
    "#### The Fortran Golden Rule \"i-inner-do\" seems to break for openmp gpu offload. \n",
    "Fortran is  [column-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order), i.e., arrays A(i,j) are arranged in memory so that A(i+1,j) is \"next to\" A(i,j). So in an i,j loop accessing A(i,j), i is better be the inner index to take advantage of the closer pacing in memory space. I.e., a construct like\n",
    "```\n",
    "do j=1,Nj;do i=1,Ni; A(i,j)=1; enddo;endo   \n",
    "```\n",
    "is \"better\" than \n",
    "```\n",
    "do i=1,Ni;do j=1,Nj; A(i,j)=1; enddo;endo \n",
    "```\n",
    "This is evident from the timings for the CPU code below where subroutines ending with \"swapij\" are of the second kind (j-inner).\n",
    "\n",
    "But that rule seems to be breaking for the gpu offload via openmp where the j-inner seems to be faster then i-inner, as in C arrays (which are row-major). This is a hint that there might be Fortran to C translation happening by the compiler.\n",
    "\n",
    "#### nvfortran -acc is default, -acc -ta=nvidia:managed is also probably default as we don't need data movement with ACC\n",
    "#### nvfortran --stdpar speeds up openmp offload. Why? What does --stdpar do?\n",
    "```\n",
    "size      time(s) iterations initial_sum      final_sum       #ompthr   subroutine\n",
    "100000000 994.535  2000    0.000066406416776  0.001709011693696 1  benchmark2d2_omp_gpu_without-stdpar\n",
    "100000000  95.527  2000    0.000066406416776  0.001709011693696 1  benchmark2d2_omp_gpu_WITH-stdpar\n",
    "```    \n",
    "\n",
    "Hint found [here](https://developer.nvidia.com/blog/using-fortran-standard-parallel-programming-for-gpu-acceleration/): \n",
    "For nvfortran, activating standard parallelism (-stdpar=gpu) automatically activates managed memory. To use OpenACC directives to control data movement along with do concurrent, use the following flags: -acc=gpu -gpu=nomanaged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8915baa",
   "metadata": {},
   "source": [
    "### Some timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578aaf74-0d66-4b64-8dfa-f41d836816fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 11 13:14:48 EST 2023\n",
      "     subroutine Aij <-- (Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   367.745    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_cpu\n",
      "     100000000   230.126    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu\n",
      "     100000000  3261.778    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu_swapij\n",
      "     100000000    55.858    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu\n",
      "     100000000    62.188    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_collapse2\n",
      "     100000000     9.631    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_collapse2_teams\n",
      "     100000000     8.819    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_collapse2_loop\n",
      "     100000000    14.100    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij\n",
      "     100000000    14.092    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij_collapse2\n",
      "     100000000    55.164    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij_collapse2_teams\n",
      "     100000000    57.996    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij_collapse2_loop\n",
      "     100000000    15.181    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu\n",
      "     100000000    14.038    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu_swapij\n",
      "     100000000     8.818    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon\n",
      "     100000000     8.819    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon_swapij\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fcc02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 11 12:48:13 EST 2023\n",
      "     subroutine Aij <-- (Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000    62.348    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu\n",
      "     100000000    56.317    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_collapse2\n",
      "     100000000     9.638    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_collapse2_teams\n",
      "     100000000     8.822    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_collapse2_loop\n",
      "     100000000    14.069    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij\n",
      "     100000000    14.100    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij_collapse2\n",
      "     100000000    55.945    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij_collapse2_teams\n",
      "     100000000    57.576    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij_collapse2_loop\n",
      "     100000000    15.047    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu\n",
      "     100000000    14.056    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu_swapij\n",
      "     100000000     8.823    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon\n",
      "     100000000     8.823    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon_swapij\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c871a-f920-46ba-88fd-c501946d8201",
   "metadata": {},
   "source": [
    "### Old gpubox 07/18/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "620f4202-4605-47db-bcb1-916489b54a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 18 16:18:08 EDT 2023\n",
      "     subroutine Aij <-- (Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   649.363    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_cpu\n",
      "     100000000   962.242    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu\n",
      "     100000000  7108.872    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu_swapij\n",
      "     100000000    54.111    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu\n",
      "     100000000    19.068    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij\n",
      "     100000000    31.745    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu\n",
      "     100000000    25.128    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu_swapij\n",
      "     100000000    29.988    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon\n",
      "     100000000    38.505    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon_swapij\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6a43d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 17 16:42:29 EDT 2023\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   603.275    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_cpu\n",
      "     100000000  1054.563    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu\n",
      "     100000000  7094.529    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu_swapij\n",
      "     100000000    54.180    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu\n",
      "     100000000    19.085    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij\n",
      "     100000000    31.399    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu\n",
      "     100000000    27.769    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu_swapij\n",
      "     100000000    30.245    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon\n",
      "     100000000    38.571    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon_swapij\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d079ce8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 17 12:35:17 EDT 2023\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   829.885    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_cpu\n",
      "     100000000   700.527    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu\n",
      "     100000000  7106.718    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu_swapij\n",
      "     100000000    54.155    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu\n",
      "     100000000    19.996    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij\n",
      "     100000000    32.078    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu\n",
      "     100000000    29.752    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_acc_gpu_swapij\n",
      "     100000000    29.807    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon\n",
      "     100000000    41.331    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon_swapij\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "babcea07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 12 18:03:13 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   429.859    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_cpu\n",
      "     100000000   433.338    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_cpu_swapij\n",
      "     100000000   215.287    2000    0.000066406416776    0.000002652284758    2     benchmark2d_omp_cpu\n",
      "     100000000     0.506    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu\n",
      "     100000000     0.446    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu_swapij\n",
      "     100000000     0.350    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu_subij\n",
      "     100000000     0.201    2000    0.000066406416776    0.000002652284758    1     benchmark2d_docon\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000  1230.186    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_cpu\n",
      "     100000000  1056.527    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu\n",
      "     100000000  7087.685    2000    0.000066406416776    0.001709011693696    2     benchmark2d2_omp_cpu_swapij\n",
      "     100000000    54.333    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu\n",
      "     100000000    15.981    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_omp_gpu_swapij\n",
      "     100000000    11.844    2000    0.000066406416776    0.001709011693696    1     benchmark2d2_docon\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d66d40b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 14 13:39:49 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   429.885    2000    0.000066406610131    0.000002652286184    1     benchmark2d_omp_cpu\n",
      "     100000000   432.379    2000    0.000066406610131    0.000002652286184    1     benchmark2d_omp_cpu_swapij\n",
      "     100000000   215.354    2000    0.000066406610131    0.000002652286184    2     benchmark2d_omp_cpu\n",
      "     100000000     0.351    2000    0.000066406610131    0.000002652286184    1     benchmark2d_omp_gpu\n",
      "     100000000     0.299    2000    0.000066406610131    0.000002652286184    1     benchmark2d_omp_gpu_swapij\n",
      "     100000000     0.198    2000    0.000066406610131    0.000002652286184    1     benchmark2d_omp_gpu_subij\n",
      "     100000000     0.160    2000    0.000066406610131    0.000002652286184    1     benchmark2d_docon\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   381.563    2000    0.000066406610131    0.001702437060885    1     benchmark2d2_omp_cpu\n",
      "     100000000   887.026    2000    0.000066406610131    0.001702437060885    2     benchmark2d2_omp_cpu\n",
      "     100000000  6251.010    2000    0.000066406610131    0.001702437060885    2     benchmark2d2_omp_cpu_swapij\n",
      "     100000000    29.245    2000    0.000066406610131    0.001702437060885    1     benchmark2d2_omp_gpu\n",
      "     100000000    10.808    2000    0.000066406610131    0.001702437060885    1     benchmark2d2_omp_gpu_swapij\n",
      "     100000000     6.467    2000    0.000066406610131    0.001702437060885    1     benchmark2d2_docon\n"
     ]
    }
   ],
   "source": [
    "##Single precision\n",
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d_float.f90 -o gpu_offload_test2d_float ; ./gpu_offload_test2d_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27d27149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 13 10:56:26 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "   100000000   767.603    2000    0.000066406416084    0.000002652284971    1           benchmark2d_omp_cpu\n",
      "   100000000   396.312    2000    0.000066406416084    0.000002652284971    2           benchmark2d_omp_cpu\n",
      "   100000000     0.673    2000    0.000066406416084    0.000002652284971    1           benchmark2d_omp_gpu\n",
      "   100000000     0.474    2000    0.000066406416084    0.000002652284971    1    benchmark2d_omp_gpu_swapij\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "   100000000  1398.757    2000    0.000066406416084    0.001709011675887    1         benchmark2d_2_omp_cpu\n",
      "   100000000   865.764    2000    0.000066406416084    0.001709011675887    2         benchmark2d_2_omp_cpu\n",
      "   100000000  6742.826    2000    0.000066406416084    0.001709011675887    2  benchmark2d_2_omp_cpu_swapij\n",
      "   100000000  1076.503    2000    0.000066406416084    0.001709011675887    1         benchmark2d_2_omp_gpu\n",
      "   100000000  1093.779    2000    0.000066406416084    0.001709011675887    1  benchmark2d_2_omp_gpu_swapij\n"
     ]
    }
   ],
   "source": [
    "#nvC\n",
    "!date; source envs.gpubox; nvc -mp=gpu  gpu_offload_test2d.c  -o gpu_offload_test2d_nvc ; ./gpu_offload_test2d_nvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cb18aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 14 10:41:46 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "   100000000  1089.756    2000    0.000066406610131    0.000002652286412    1           benchmark2d_omp_cpu\n",
      "   100000000   552.592    2000    0.000066406610131    0.000002652286412    2           benchmark2d_omp_cpu\n",
      "   100000000     1.420    2000    0.000066406610131    0.000002652286412    1           benchmark2d_omp_gpu\n",
      "   100000000     1.217    2000    0.000066406610131    0.000002652286412    1    benchmark2d_omp_gpu_swapij\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "   100000000  1487.218    2000    0.000066406610131    0.001702437060885    1         benchmark2d_2_omp_cpu\n",
      "   100000000   744.085    2000    0.000066406610131    0.001702437060885    2         benchmark2d_2_omp_cpu\n",
      "   100000000  4166.676    2000    0.000066406610131    0.001702437060885    2  benchmark2d_2_omp_cpu_swapij\n",
      "   100000000   620.615    2000    0.000066406610131    0.001702437060885    1         benchmark2d_2_omp_gpu\n",
      "   100000000   909.522    2000    0.000066406610131    0.001702437060885    1  benchmark2d_2_omp_gpu_swapij\n"
     ]
    }
   ],
   "source": [
    "##Single precision\n",
    "#nvC\n",
    "!date; source envs.gpubox; nvc -mp=gpu  gpu_offload_test2d_float.c  -o gpu_offload_test2d_float_nvc ; ./gpu_offload_test2d_float_nvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef7b3e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 13 15:46:17 EDT 2023\n",
      "clang-14: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mCUDA version is newer than the latest supported version 11.5 [-Wunknown-cuda-version]\u001b[0m\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "   100000000   430.594    2000    0.000066406416811    0.000002652284762    1           benchmark2d_omp_cpu\n",
      "   100000000   215.794    2000    0.000066406416811    0.000002652284762    2           benchmark2d_omp_cpu\n",
      "   100000000    19.083    2000    0.000066406416811    0.000002652284762    1           benchmark2d_omp_gpu\n",
      "   100000000    19.126    2000    0.000066406416811    0.000002652284762    1    benchmark2d_omp_gpu_swapij\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "   100000000   642.038    2000    0.000066406416811    0.001709011694582    1         benchmark2d_2_omp_cpu\n",
      "   100000000   279.017    2000    0.000066406416811    0.001709011694582    2         benchmark2d_2_omp_cpu\n",
      "   100000000  4865.962    2000    0.000066406416811    0.001709011694582    2  benchmark2d_2_omp_cpu_swapij\n",
      "   100000000  2256.968    2000    0.000066406416811    0.001709011694582    1         benchmark2d_2_omp_gpu\n",
      "   100000000  2627.058    2000    0.000066406416811    0.001709011694582    1  benchmark2d_2_omp_gpu_swapij\n"
     ]
    }
   ],
   "source": [
    "#CLANG\n",
    "!date; ulimit -s unlimited; /home/Niki.Zadeh/opt/llvm/install/bin/clang  -L/opt/gcc/11.3.0/lib64  -lm -O3 -fopenmp  -fopenmp-targets=nvptx64  gpu_offload_test2d.c  -o gpu_offload_test2d_clang; ./gpu_offload_test2d_clang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592b392",
   "metadata": {},
   "source": [
    "## 06/30/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04579640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000     0.505    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu                               \n",
      "     100000000     0.381    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu_subij                         \n",
      "     100000000     0.235    2000    0.000066406416776    0.000002652284758    1     benchmark2d_docon                                 \n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   618.343    2000    0.000066406416776    0.002417809226842    1     benchmark2d2_omp_cpu                              \n",
      "     100000000    38.014    2000    0.000066406416776    0.001984539257347    1     benchmark2d2_omp_gpu                              \n",
      "     100000000     5.014    2000    0.000066406416776    0.001835053249559    1     benchmark2d2_docon                                \n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d\n",
    "\n",
    "#Time to solution for a few simple problems.\n",
    "#\n",
    "#fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     100000000   429.689    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp                                   \n",
    "#     100000000   235.189    2000    0.000066406416776    0.000002652284758    2     benchmark2d_omp                                   \n",
    "##\n",
    "#     100000000     0.458    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu                               \n",
    "#     100000000     0.353    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu_subij                         \n",
    "#     100000000     0.189    2000    0.000066406416776    0.000002652284758    1     benchmark2d_docon                \n",
    "#\n",
    "#     200000000     0.893    2000    0.000033203208388    0.000001326142379    1     benchmark2d_omp_gpu                               \n",
    "#     200000000     0.737    2000    0.000033203208388    0.000001326142379    1     benchmark2d_omp_gpu_subij                         \n",
    "#     200000000     0.444    2000    0.000033203208388    0.000001326142379    1     benchmark2d_docon                                 \n",
    "#\n",
    "#    1000000000    10.061    2000    0.000006640641678    0.000000265228476    1     benchmark2d_omp_gpu                               \n",
    "#    1000000000     9.850    2000    0.000006640641678    0.000000265228476    1     benchmark2d_omp_gpu_subij                         \n",
    "#    1000000000     1.995    2000    0.000006640641678    0.000000265228476    1     benchmark2d_docon                                 \n",
    "#\n",
    "#     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     100000000   620.114    2000    0.000066406416776    0.002417809226842    1     benchmark2d2_omp_cpu                              \n",
    "#     100000000    38.148    2000    0.000066406416776    0.001984566887412    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     4.982    2000    0.000066406416776    0.001835117539473    1     benchmark2d2_docon \n",
    "#     100000000   618.343    2000    0.000066406416776    0.002417809226842    1     benchmark2d2_omp_cpu                              \n",
    "#     100000000    38.014    2000    0.000066406416776    0.001984539257347    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     5.014    2000    0.000066406416776    0.001835053249559    1     benchmark2d2_docon                                \n",
    "#     100000000    38.217    2000    0.000066406416776    0.001984416922111    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     4.969    2000    0.000066406416776    0.001835279846870    1     benchmark2d2_docon   \n",
    "#     100000000    38.183    2000    0.000066406416776    0.001984440023023    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     5.052    2000    0.000066406416776    0.001835121322498    1     benchmark2d2_docon \n",
    "#     100000000    38.132    2000    0.000066406416776    0.001984400154502    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     4.991    2000    0.000066406416776    0.001835447374488    1     benchmark2d2_docon             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf49cd",
   "metadata": {},
   "source": [
    "## Older results\n",
    "\n",
    "### openMP on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source envs.gpubox; \\rm gpu_offload_benchmark2d ; nvfortran -mp gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edf0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n",
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000    58.132    2000    0.000066406416776    0.000002652284758   16     benchmark2d_omp                                   \n"
     ]
    }
   ],
   "source": [
    "##This test could take too long to run on CPU\n",
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "!echo '16' | ./gpu_offload_benchmark2d\n",
    "#      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
    "#    1600000000 12306.969    2000    0.000016602849567    0.000000663121053    1     benchmark2d_omp \n",
    "#     100000000   770.307    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp\n",
    "#     100000000   387.471    2000    0.000066406416776    0.000002652284758    2     benchmark2d_omp\n",
    "#     100000000   200.788    2000    0.000066406416776    0.000002652284758    4     benchmark2d_omp\n",
    "#     100000000    99.781    2000    0.000066406416776    0.000002652284758    8     benchmark2d_omp\n",
    "#     100000000    54.811    2000    0.000066406416776    0.000002652284758   16     benchmark2d_omp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5e5f0",
   "metadata": {},
   "source": [
    "### openMP offload to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef5547c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox; \\rm gpu_offload_benchmark2d ; nvfortran -mp=gpu gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5bad60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.438    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n",
      "     100000000     1.470    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n",
      "     100000000     1.476    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n",
      "     100000000     1.450    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-1' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#  1600000000     9.358    2000    0.000016602849567    0.000000663121053    0     benchmark2d_omp_gpu\n",
    "#   100000000     1.438    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbae4e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.174    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n",
      "     100000000     1.086    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n",
      "     100000000     1.193    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n",
      "     100000000     1.222    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-2' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "# 1600000000     7.342    2000    0.000016602849567    0.000000663121053    0     benchmark2d_omp_gpu_teams \n",
    "#  100000000     1.086    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad218b",
   "metadata": {},
   "source": [
    "The following is a hack to use 2 GPU devices by deviding the 2d array into 2 blocks.It gets a better performance for larger arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0096dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.164    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n",
      "     100000000     1.348    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n",
      "     100000000     1.153    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n",
      "     100000000     1.303    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-3' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     9.016    2000    0.000016602849567    0.000000663121053    0     benchmark2d_omp_gpu_teams_2devs\n",
    "# 100000000     1.153    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df73d4",
   "metadata": {},
   "source": [
    "## openACC offload to GPU\n",
    "### A) managed mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c85d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox;\\rm ./gpu_offload_benchmark2d ; nvfortran -mp -acc -ta=nvidia:managed gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76ed3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.726    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     0.748    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     0.666    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     0.741    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-5' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     2.979    2000    0.000016602849567    0.000000663121053    0     benchmark2d_acc\n",
    "# 100000000     0.666    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a44500",
   "metadata": {},
   "source": [
    "The following is a hack to use 2 GPU devices by deviding the 2d array into 2 blocks.It gets a better performance for larger arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79aca939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.631    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n",
      "     100000000     0.573    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n",
      "     100000000     0.666    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n",
      "     100000000     0.668    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-52' | ./gpu_offload_benchmark2d\n",
    "\n",
    "#1600000000     2.155    2000    0.000016602849567    0.000000663121053    0     benchmark2d_acc_2dev   \n",
    "# 100000000     0.573    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662aa04c",
   "metadata": {},
   "source": [
    "### B) non-managed mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f63586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox;\\rm ./gpu_offload_benchmark2d ; nvfortran -mp -acc gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a434d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.169    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     1.114    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     1.291    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     1.206    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-5' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     7.428    2000    0.000016602849567    0.000000663121053    0     benchmark2d_acc\n",
    "# 100000000     1.114    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44367fd3",
   "metadata": {},
   "source": [
    "## do concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8b34df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox; \\rm gpu_offload_benchmark2d ; nvfortran -mp -stdpar gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af8c5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.778    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n",
      "     100000000     0.718    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n",
      "     100000000     0.784    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n",
      "     100000000     0.709    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-4' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     2.941    2000    0.000016602849567    0.000000663121053    0     benchmark2d_docon   \n",
    "# 100000000     0.709    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6be367",
   "metadata": {},
   "source": [
    "The following is a hack to use 2 GPU devices by deviding the 2d array into 2 blocks.It gets a better performance for larger arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9520c5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.692    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n",
      "     100000000     0.695    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n",
      "     100000000     0.696    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n",
      "     100000000     0.643    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-42' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "# 1600000000     2.152    2000    0.000016602849567    0.000000663121053    0     benchmark2d_docon_2dev_hack\n",
    "#  100000000     0.643    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e679fd7",
   "metadata": {},
   "source": [
    "### Quick test for gpu offload single precision array\n",
    "This is a Fortran program to  quickly test gpu offload via openmp and do concurrent. It has been run on Intel (ifx) and Nvidia (nvfortran) GPU patforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4748c",
   "metadata": {},
   "source": [
    "## Intel GPUs\n",
    "Here are some timing numbers I optained on Intel devcloud platform for Intel GPU's under Intel ifx and some corresponding numbers for nvidia of the same size. Intel GPUs in this platform could not handle double precision arrays, so I had to reduce real\\*8 used above to real. Also these GPUs could not handle the array size used above, so I had to reduce the size. For details see  [https://github.com/nikizadehgfdl/platforms/blob/master/samples/gpu/openmp/test_omp_gpu.f90](test_omp_gpu.f90).\n",
    "\n",
    "```\n",
    "Intel GPU under Intel ix -O2\n",
    "!      size      time(s) iterations initial_sum     final_sum        omp_nthreads    subroutine\n",
    "!      16000000     0.727     200    0.000165990830283    0.000015737356080    1     benchmark2d_omp_gpu\n",
    "!      16000000     0.069     200    0.000165990830283    0.000015737356080    1     benchmark2d_docon        \n",
    "!      16000000     1.355    2000    0.000165990830283    0.000006629713880    1     benchmark2d_omp_gpu\n",
    "!      16000000     0.502    2000    0.000165990830283    0.000006629713880    1     benchmark2d_docon\n",
    "!     100000000     4.387    2000    0.000066406377300    0.000002652283911    1     benchmark2d_omp_gpu\n",
    "!     100000000     3.140    2000    0.000066406377300    0.000002652283911    1     benchmark2d_docon\n",
    "!     400000000    14.626    2000    0.000033204814827    0.000001326215852    1     benchmark2d_omp_gpu\n",
    "!     400000000    12.551    2000    0.000033204814827    0.000001326215852    1     benchmark2d_docon   \n",
    "!     16000000 bombs\n",
    "Nvidia GPU under nvfortran\n",
    "!      16000000     0.023     200    0.000165991063113    0.000015737357899    1     benchmark2d_omp_gpu              \n",
    "!      16000000     0.024     200    0.000165991063113    0.000015737357899    1     benchmark2d_docon  \n",
    "!      16000000     0.080    2000    0.000165991063113    0.000006629711152    1     benchmark2d_omp_gpu                 !      16000000     0.035    2000    0.000165991063113    0.000006629711152    1     benchmark2d_docon       \n",
    "!     100000000     0.245    2000    0.000066406464612    0.000002652284593    1     benchmark2d_omp_gpu             \n",
    "!     100000000     0.144    2000    0.000066406464612    0.000002652284593    1     benchmark2d_docon\n",
    "!\n",
    "!     100000000   215.581    2000    0.000066406464612    0.000002652284593    2     benchmark2d_omp_cpu\n",
    "!     100000000   429.280    2000    0.000066406464612    0.000002652284593    1     benchmark2d_omp_cpu\n",
    "!\n",
    "!     400000000     0.822    2000    0.000033204873034    0.000001326215056    1     benchmark2d_omp_gpu                 !     400000000     0.430    2000    0.000033204873034    0.000001326215056    1     benchmark2d_docon                   !    1600000000     3.203    2000    0.000016602891264    0.000000663109006    1     benchmark2d_omp_gpu            \n",
    "!    1600000000     1.919    2000    0.000016602891264    0.000000663109006    1     benchmark2d_docon   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c6d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n",
      "rm: cannot remove ‘./gpu_offload_test2d’: No such file or directory\n",
      "      size      time(s) iterations initial_sum     final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.563    2000    0.000066406464612    0.000002652284593    1     benchmark2d_omp_gpu                               \n",
      "     100000000     0.440    2000    0.000066406464612    0.000002652284593    1     benchmark2d_docon                                 \n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox;\\rm ./gpu_offload_test2d; nvfortran -O2 -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d;./gpu_offload_test2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
