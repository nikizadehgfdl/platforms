{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e92eef7",
   "metadata": {},
   "source": [
    "# GPU offloading in Fortran\n",
    "This notebook guides through a few test programs to try and study gpu offloading in Fortran. The main routine is a simple 2d array calculation:\n",
    "```\n",
    "do j=0,n-1;do i=0,m-1\n",
    "     iter=0\n",
    "     do while (iter < iter_max)\n",
    "        A(i,j) = A(i,j)*(A(i,j)-1.0)\n",
    "        iter = iter+1\n",
    "     enddo\n",
    "enddo; enddo\n",
    "```\n",
    "\n",
    "The runtime is proportional to the size of the array (m\\*n) as well as the number of iterations (iter_max).   \n",
    "The code inside the ij loop is supposed to simulate an ij-independent workload. We realize that usually such  embarassingly parallel workload does not represent the ones that arise in science and engineering. It was designed only as a starting point to try various offloading schemes and compare their potential utility in Fortran.\n",
    "\n",
    "## Executive Summary\n",
    "- Offload via Fortran \"do concurrent\" scheme seems to be on par with  openACC \"manged mode\"  in speed.\n",
    "- Offload via openMP \"target\"              scheme seems to be on par with  openACC \"non-manged mode\" in speed.\n",
    "- Both of these schemes are available and were tested in nvfortran for Nvidia GPUs and ifx for Intel GPUs. \n",
    "- However the cross-compatibility (using ifx to offload to Nvidia Or using nvfortran to offload to Intel device) was not tested. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d34522",
   "metadata": {},
   "source": [
    "### Simple array test on gfdl gpubox\n",
    "\n",
    "#### The bad\n",
    "- For the more complex problem the GPU answers (final_sum) are not repeatable and are also too different from CPU answers! Why?\n",
    "\n",
    "#### The good\n",
    "- For the simpler problem the GPU and CPU answers are the same.\n",
    "- 'do concurrent' is much fater than openmp offload, partularly for larger problems. Why?\n",
    "- Note the 4000x speedup on GPU relative to single thread CPU for a fully vectorizable subroutine. Ain't that weird?\n",
    "- The GPU/CPU speedup reduces to 15x for a more realistic subroutien like 4-point average (Laplace operator).\n",
    "- Timing to solution scales linearly with problem size for 'do concurrent' but lags behind for openmp. Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7953f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 10 14:22:07 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "      10000000    43.297    2000    0.000066346590889    0.000002649843222    1     benchmark2d_omp_cpu\n",
      "      10000000    43.248    2000    0.000066346590889    0.000002649843222    1     benchmark2d_omp_cpu_swapij\n",
      "      10000000    21.706    2000    0.000066346590889    0.000002649843222    2     benchmark2d_omp_cpu\n",
      "      10000000     0.399    2000    0.000066346590889    0.000002649843222    1     benchmark2d_omp_gpu\n",
      "      10000000     0.065    2000    0.000066346590889    0.000002649843222    1     benchmark2d_omp_gpu_swapij\n",
      "      10000000     0.251    2000    0.000066346590889    0.000002649843222    1     benchmark2d_omp_gpu_subij\n",
      "      10000000     0.045    2000    0.000066346590889    0.000002649843222    1     benchmark2d_docon\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)**2\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "      10000000    70.073    2000    0.000066346590889    0.000000046104656    1     benchmark2d1_omp_cpu\n",
      "      10000000    35.177    2000    0.000066346590889    0.000000046104656    2     benchmark2d1_omp_cpu\n",
      "      10000000     0.387    2000    0.000066346590889    0.000000046104656    1     benchmark2d1_omp_gpu\n",
      "      10000000     0.076    2000    0.000066346590889    0.000000046104656    1     benchmark2d1_omp_gpu_swapij\n",
      "      10000000     0.048    2000    0.000066346590889    0.000000046104656    1     benchmark2d1_docon\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "      10000000    61.639    2000    0.000066346590889    0.002407781721004    1     benchmark2d2_omp_cpu\n",
      "      10000000    32.982    2000    0.000066346590889    0.002407781495202    2     benchmark2d2_omp_cpu\n",
      "      10000000    52.230    2000    0.000066346590889    0.002407781721004    2     benchmark2d2_omp_cpu_swapij\n",
      "      10000000    11.698    2000    0.000066346590889    0.001977514249181    1     benchmark2d2_omp_gpu\n",
      "      10000000     1.194    2000    0.000066346590889    0.001970129924378    1     benchmark2d2_omp_gpu_swapij\n",
      "      10000000     0.467    2000    0.000066346590889    0.001705690609948    1     benchmark2d2_docon\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ffb5254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul  7 15:25:16 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "       1000000     4.395    2000    0.000663465908885    0.000026498432222    1     benchmark2d_omp_cpu\n",
      "       1000000     2.340    2000    0.000663465908885    0.000026498432222    2     benchmark2d_omp_cpu\n",
      "       1000000     0.121    2000    0.000663465908885    0.000026498432222    1     benchmark2d_omp_gpu\n",
      "       1000000     0.029    2000    0.000663465908885    0.000026498432222    1     benchmark2d_omp_gpu_subij\n",
      "       1000000     0.006    2000    0.000663465908885    0.000026498432222    1     benchmark2d_docon\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "       1000000     5.895    2000    0.000663465908885    0.024077817210038    1     benchmark2d2_omp_cpu\n",
      "       1000000     3.152    2000    0.000663465908885    0.024077814952025    2     benchmark2d2_omp_cpu\n",
      "       1000000     1.167    2000    0.000663465908885    0.019788540723711    1     benchmark2d2_omp_gpu\n",
      "       1000000     0.064    2000    0.000663465908885    0.017047469018848    1     benchmark2d2_docon\n"
     ]
    }
   ],
   "source": [
    "##nvFORTRAN\n",
    "!date; source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf8c2f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul  7 15:25:52 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     1000000   7.671    2000    0.000663465903206    0.000026498434366    1           benchmark2d_omp_cpu\n",
      "     1000000   3.922    2000    0.000663465903206    0.000026498434366    2           benchmark2d_omp_cpu\n",
      "     1000000   0.265    2000    0.000663465903206    0.000026498434366    1           benchmark2d_omp_gpu\n",
      "     1000000   0.030    2000    0.000663465903206    0.000026498434366    1     benchmark2d_omp_gpu_subij\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     1000000  10.844    2000    0.000663465903206    0.024077816985593    1         benchmark2d_2_omp_cpu\n",
      "     1000000   5.554    2000    0.000663465903206    0.024077814727579    2         benchmark2d_2_omp_cpu\n",
      "     1000000   6.472    2000    0.000663465903206    0.019781126900958    1         benchmark2d_2_omp_gpu\n"
     ]
    }
   ],
   "source": [
    "#nvC\n",
    "!date; source envs.gpubox; nvc -mp=gpu  gpu_offload_test2d.c  -o gpu_offload_test2d_nvc ; ./gpu_offload_test2d_nvc\n",
    "##Single precision float\n",
    "#     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     1000000  11.014    2000    0.000663466402330    0.000026498402804    1           benchmark2d_omp_cpu\n",
    "#     1000000   5.659    2000    0.000663466402330    0.000026498402804    2           benchmark2d_omp_cpu\n",
    "#     1000000   0.262    2000    0.000663466402330    0.000026498402804    1           benchmark2d_omp_gpu\n",
    "#     1000000   0.100    2000    0.000663466402330    0.000026498402804    1     benchmark2d_omp_gpu_subij\n",
    "#     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     1000000  14.050    2000    0.000663466402330    0.024067711085081    1         benchmark2d_2_omp_cpu\n",
    "#     1000000   7.381    2000    0.000663466402330    0.024067729711533    2         benchmark2d_2_omp_cpu\n",
    "#     1000000   3.490    2000    0.000663466402330    0.019762143492699    1         benchmark2d_2_omp_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee58cf99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul  7 15:26:32 EDT 2023\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     1000000   7.763    2000    0.000663465903206    0.000026498434366    1           benchmark2d_omp_cpu\n",
      "     1000000   3.888    2000    0.000663465903206    0.000026498434366    2           benchmark2d_omp_cpu\n",
      "     1000000   0.229    2000    0.000663465903206    0.000026498434366    1           benchmark2d_omp_gpu\n",
      "     1000000   0.030    2000    0.000663465903206    0.000026498434366    1     benchmark2d_omp_gpu_subij\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     1000000  10.788    2000    0.000663465903206    0.024077816985599    1         benchmark2d_2_omp_cpu\n",
      "     1000000   5.524    2000    0.000663465903206    0.024077814727585    2         benchmark2d_2_omp_cpu\n",
      "     1000000   6.512    2000    0.000663465903206    0.019780932501261    1         benchmark2d_2_omp_gpu\n"
     ]
    }
   ],
   "source": [
    "#nvC\n",
    "!date; source envs.gpubox; nvc -mp=gpu -O3 gpu_offload_test2d.c  -o gpu_offload_test2d_nvc ; ./gpu_offload_test2d_nvc\n",
    "##Single precision float\n",
    "#     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     1000000  10.914    2000    0.000663466169499    0.000026498426450    1           benchmark2d_omp_cpu\n",
    "#     1000000   5.584    2000    0.000663466169499    0.000026498426450    2           benchmark2d_omp_cpu\n",
    "#     1000000   0.317    2000    0.000663466169499    0.000026498426450    1           benchmark2d_omp_gpu\n",
    "#     1000000   0.088    2000    0.000663466169499    0.000026498426450    1     benchmark2d_omp_gpu_subij\n",
    "#     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     1000000  10.786    2000    0.000663466169499    0.024076737463474    1         benchmark2d_2_omp_cpu\n",
    "#     1000000   5.515    2000    0.000663466169499    0.024076731875539    2         benchmark2d_2_omp_cpu\n",
    "#     1000000   3.438    2000    0.000663466169499    0.019761022180319    1         benchmark2d_2_omp_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7b3e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul  7 15:27:47 EDT 2023\n",
      "clang-14: \u001b[0;1;35mwarning: \u001b[0m\u001b[1mCUDA version is newer than the latest supported version 11.5 [-Wunknown-cuda-version]\u001b[0m\n",
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     1000000   4.423    2000    0.000663465910619    0.000026498432384    1           benchmark2d_omp_cpu\n",
      "     1000000   2.240    2000    0.000663465910619    0.000026498432384    2           benchmark2d_omp_cpu\n",
      "     1000000   0.315    2000    0.000663465910619    0.000026498432384    1           benchmark2d_omp_gpu\n",
      "     1000000   0.194    2000    0.000663465910619    0.000026498432384    1     benchmark2d_omp_gpu_subij\n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     1000000   7.749    2000    0.000663465910619    0.024077817255628    1         benchmark2d_2_omp_cpu\n",
      "     1000000   3.930    2000    0.000663465910619    0.024077814997615    2         benchmark2d_2_omp_cpu\n",
      "     1000000  14.694    2000    0.000663465910619    0.019804657740723    1         benchmark2d_2_omp_gpu\n"
     ]
    }
   ],
   "source": [
    "#CLANG\n",
    "!date; ulimit -s unlimited; /home/Niki.Zadeh/opt/llvm/install/bin/clang  -L/opt/gcc/11.3.0/lib64  -lm -O3 -fopenmp  -fopenmp-targets=nvptx64  gpu_offload_test2d.c  -o gpu_offload_test2d_clang; ./gpu_offload_test2d_clang\n",
    "###Single precision float\n",
    "#     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     1000000   7.663    2000    0.000663466402330    0.000026498402804    1           benchmark2d_omp_cpu\n",
    "#     1000000   3.890    2000    0.000663466402330    0.000026498402804    2           benchmark2d_omp_cpu\n",
    "#     1000000   0.735    2000    0.000663466402330    0.000026498402804    1           benchmark2d_omp_gpu\n",
    "#     1000000   0.574    2000    0.000663466402330    0.000026498402804    1     benchmark2d_omp_gpu_subij\n",
    "#     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4 \n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     1000000  10.419    2000    0.000663466402330    0.024067709222436    1         benchmark2d_2_omp_cpu\n",
    "#     1000000   5.291    2000    0.000663466402330    0.024067727848887    2         benchmark2d_2_omp_cpu\n",
    "#     1000000  11.400    2000    0.000663466402330    0.019807141274214    1         benchmark2d_2_omp_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592b392",
   "metadata": {},
   "source": [
    "## 06/30/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04579640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000     0.505    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu                               \n",
      "     100000000     0.381    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu_subij                         \n",
      "     100000000     0.235    2000    0.000066406416776    0.000002652284758    1     benchmark2d_docon                                 \n",
      "     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
      "     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
      "     100000000   618.343    2000    0.000066406416776    0.002417809226842    1     benchmark2d2_omp_cpu                              \n",
      "     100000000    38.014    2000    0.000066406416776    0.001984539257347    1     benchmark2d2_omp_gpu                              \n",
      "     100000000     5.014    2000    0.000066406416776    0.001835053249559    1     benchmark2d2_docon                                \n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox; nvfortran -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d ; ./gpu_offload_test2d\n",
    "\n",
    "#Time to solution for a few simple problems.\n",
    "#\n",
    "#fully vectorizable subroutine Aij=Aij*(Aij-1)\n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     100000000   429.689    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp                                   \n",
    "#     100000000   235.189    2000    0.000066406416776    0.000002652284758    2     benchmark2d_omp                                   \n",
    "##\n",
    "#     100000000     0.458    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu                               \n",
    "#     100000000     0.353    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp_gpu_subij                         \n",
    "#     100000000     0.189    2000    0.000066406416776    0.000002652284758    1     benchmark2d_docon                \n",
    "#\n",
    "#     200000000     0.893    2000    0.000033203208388    0.000001326142379    1     benchmark2d_omp_gpu                               \n",
    "#     200000000     0.737    2000    0.000033203208388    0.000001326142379    1     benchmark2d_omp_gpu_subij                         \n",
    "#     200000000     0.444    2000    0.000033203208388    0.000001326142379    1     benchmark2d_docon                                 \n",
    "#\n",
    "#    1000000000    10.061    2000    0.000006640641678    0.000000265228476    1     benchmark2d_omp_gpu                               \n",
    "#    1000000000     9.850    2000    0.000006640641678    0.000000265228476    1     benchmark2d_omp_gpu_subij                         \n",
    "#    1000000000     1.995    2000    0.000006640641678    0.000000265228476    1     benchmark2d_docon                                 \n",
    "#\n",
    "#     non-vectorizable subroutine Aij=(Ai-1,j + Ai+1,j + Ai,j-1 + Ai,j+1)/4\n",
    "#     size        time(s) iterations initial_sum          final_sum        #ompthr    subroutine\n",
    "#     100000000   620.114    2000    0.000066406416776    0.002417809226842    1     benchmark2d2_omp_cpu                              \n",
    "#     100000000    38.148    2000    0.000066406416776    0.001984566887412    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     4.982    2000    0.000066406416776    0.001835117539473    1     benchmark2d2_docon \n",
    "#     100000000   618.343    2000    0.000066406416776    0.002417809226842    1     benchmark2d2_omp_cpu                              \n",
    "#     100000000    38.014    2000    0.000066406416776    0.001984539257347    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     5.014    2000    0.000066406416776    0.001835053249559    1     benchmark2d2_docon                                \n",
    "#     100000000    38.217    2000    0.000066406416776    0.001984416922111    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     4.969    2000    0.000066406416776    0.001835279846870    1     benchmark2d2_docon   \n",
    "#     100000000    38.183    2000    0.000066406416776    0.001984440023023    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     5.052    2000    0.000066406416776    0.001835121322498    1     benchmark2d2_docon \n",
    "#     100000000    38.132    2000    0.000066406416776    0.001984400154502    1     benchmark2d2_omp_gpu                              \n",
    "#     100000000     4.991    2000    0.000066406416776    0.001835447374488    1     benchmark2d2_docon             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf49cd",
   "metadata": {},
   "source": [
    "## Older results\n",
    "\n",
    "### openMP on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source envs.gpubox; \\rm gpu_offload_benchmark2d ; nvfortran -mp gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edf0356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n",
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000    58.132    2000    0.000066406416776    0.000002652284758   16     benchmark2d_omp                                   \n"
     ]
    }
   ],
   "source": [
    "##This test could take too long to run on CPU\n",
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "!echo '16' | ./gpu_offload_benchmark2d\n",
    "#      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
    "#    1600000000 12306.969    2000    0.000016602849567    0.000000663121053    1     benchmark2d_omp \n",
    "#     100000000   770.307    2000    0.000066406416776    0.000002652284758    1     benchmark2d_omp\n",
    "#     100000000   387.471    2000    0.000066406416776    0.000002652284758    2     benchmark2d_omp\n",
    "#     100000000   200.788    2000    0.000066406416776    0.000002652284758    4     benchmark2d_omp\n",
    "#     100000000    99.781    2000    0.000066406416776    0.000002652284758    8     benchmark2d_omp\n",
    "#     100000000    54.811    2000    0.000066406416776    0.000002652284758   16     benchmark2d_omp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5e5f0",
   "metadata": {},
   "source": [
    "### openMP offload to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef5547c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox; \\rm gpu_offload_benchmark2d ; nvfortran -mp=gpu gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5bad60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.438    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n",
      "     100000000     1.470    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n",
      "     100000000     1.476    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n",
      "     100000000     1.450    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu                               \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-1' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#  1600000000     9.358    2000    0.000016602849567    0.000000663121053    0     benchmark2d_omp_gpu\n",
    "#   100000000     1.438    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbae4e01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.174    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n",
      "     100000000     1.086    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n",
      "     100000000     1.193    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n",
      "     100000000     1.222    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams                         \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-2' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "# 1600000000     7.342    2000    0.000016602849567    0.000000663121053    0     benchmark2d_omp_gpu_teams \n",
    "#  100000000     1.086    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad218b",
   "metadata": {},
   "source": [
    "The following is a hack to use 2 GPU devices by deviding the 2d array into 2 blocks.It gets a better performance for larger arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0096dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.164    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n",
      "     100000000     1.348    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n",
      "     100000000     1.153    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n",
      "     100000000     1.303    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs                   \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-3' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     9.016    2000    0.000016602849567    0.000000663121053    0     benchmark2d_omp_gpu_teams_2devs\n",
    "# 100000000     1.153    2000    0.000066406416776    0.000002652284758    0     benchmark2d_omp_gpu_teams_2devs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df73d4",
   "metadata": {},
   "source": [
    "## openACC offload to GPU\n",
    "### A) managed mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c85d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox;\\rm ./gpu_offload_benchmark2d ; nvfortran -mp -acc -ta=nvidia:managed gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76ed3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.726    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     0.748    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     0.666    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     0.741    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-5' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     2.979    2000    0.000016602849567    0.000000663121053    0     benchmark2d_acc\n",
    "# 100000000     0.666    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a44500",
   "metadata": {},
   "source": [
    "The following is a hack to use 2 GPU devices by deviding the 2d array into 2 blocks.It gets a better performance for larger arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79aca939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.631    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n",
      "     100000000     0.573    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n",
      "     100000000     0.666    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n",
      "     100000000     0.668    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev                              \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-52' | ./gpu_offload_benchmark2d\n",
    "\n",
    "#1600000000     2.155    2000    0.000016602849567    0.000000663121053    0     benchmark2d_acc_2dev   \n",
    "# 100000000     0.573    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc_2dev    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662aa04c",
   "metadata": {},
   "source": [
    "### B) non-managed mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f63586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox;\\rm ./gpu_offload_benchmark2d ; nvfortran -mp -acc gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98a434d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     1.169    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     1.114    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     1.291    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n",
      "     100000000     1.206    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc                                   \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-5' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     7.428    2000    0.000016602849567    0.000000663121053    0     benchmark2d_acc\n",
    "# 100000000     1.114    2000    0.000066406416776    0.000002652284758    0     benchmark2d_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44367fd3",
   "metadata": {},
   "source": [
    "## do concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8b34df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox; \\rm gpu_offload_benchmark2d ; nvfortran -mp -stdpar gpu_offload_benchmark2d.f90 -o gpu_offload_benchmark2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5af8c5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.778    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n",
      "     100000000     0.718    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n",
      "     100000000     0.784    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n",
      "     100000000     0.709    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon                                 \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-4' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "#1600000000     2.941    2000    0.000016602849567    0.000000663121053    0     benchmark2d_docon   \n",
    "# 100000000     0.709    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6be367",
   "metadata": {},
   "source": [
    "The following is a hack to use 2 GPU devices by deviding the 2d array into 2 blocks.It gets a better performance for larger arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9520c5f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.692    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n",
      "     100000000     0.695    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n",
      "     100000000     0.696    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n",
      "     100000000     0.643    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack                       \n"
     ]
    }
   ],
   "source": [
    "print(\"      size      time(s) iterations initial_sum          final_sum        omp_nthreads    subroutine\")\n",
    "for i in range(1,5):\n",
    "    !echo '-42' | ./gpu_offload_benchmark2d\n",
    "    \n",
    "# 1600000000     2.152    2000    0.000016602849567    0.000000663121053    0     benchmark2d_docon_2dev_hack\n",
    "#  100000000     0.643    2000    0.000066406416776    0.000002652284758    0     benchmark2d_docon_2dev_hack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e679fd7",
   "metadata": {},
   "source": [
    "### Quick test for gpu offload single precision array\n",
    "This is a Fortran program to  quickly test gpu offload via openmp and do concurrent. It has been run on Intel (ifx) and Nvidia (nvfortran) GPU patforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4748c",
   "metadata": {},
   "source": [
    "## Intel GPUs\n",
    "Here are some timing numbers I optained on Intel devcloud platform for Intel GPU's under Intel ifx and some corresponding numbers for nvidia of the same size. Intel GPUs in this platform could not handle double precision arrays, so I had to reduce real\\*8 used above to real. Also these GPUs could not handle the array size used above, so I had to reduce the size. For details see  [https://github.com/nikizadehgfdl/platforms/blob/master/samples/gpu/openmp/test_omp_gpu.f90](test_omp_gpu.f90).\n",
    "\n",
    "```\n",
    "Intel GPU under Intel ix -O2\n",
    "!      size      time(s) iterations initial_sum     final_sum        omp_nthreads    subroutine\n",
    "!      16000000     0.727     200    0.000165990830283    0.000015737356080    1     benchmark2d_omp_gpu\n",
    "!      16000000     0.069     200    0.000165990830283    0.000015737356080    1     benchmark2d_docon        \n",
    "!      16000000     1.355    2000    0.000165990830283    0.000006629713880    1     benchmark2d_omp_gpu\n",
    "!      16000000     0.502    2000    0.000165990830283    0.000006629713880    1     benchmark2d_docon\n",
    "!     100000000     4.387    2000    0.000066406377300    0.000002652283911    1     benchmark2d_omp_gpu\n",
    "!     100000000     3.140    2000    0.000066406377300    0.000002652283911    1     benchmark2d_docon\n",
    "!     400000000    14.626    2000    0.000033204814827    0.000001326215852    1     benchmark2d_omp_gpu\n",
    "!     400000000    12.551    2000    0.000033204814827    0.000001326215852    1     benchmark2d_docon   \n",
    "!     16000000 bombs\n",
    "Nvidia GPU under nvfortran\n",
    "!      16000000     0.023     200    0.000165991063113    0.000015737357899    1     benchmark2d_omp_gpu              \n",
    "!      16000000     0.024     200    0.000165991063113    0.000015737357899    1     benchmark2d_docon  \n",
    "!      16000000     0.080    2000    0.000165991063113    0.000006629711152    1     benchmark2d_omp_gpu                 !      16000000     0.035    2000    0.000165991063113    0.000006629711152    1     benchmark2d_docon       \n",
    "!     100000000     0.245    2000    0.000066406464612    0.000002652284593    1     benchmark2d_omp_gpu             \n",
    "!     100000000     0.144    2000    0.000066406464612    0.000002652284593    1     benchmark2d_docon\n",
    "!\n",
    "!     100000000   215.581    2000    0.000066406464612    0.000002652284593    2     benchmark2d_omp_cpu\n",
    "!     100000000   429.280    2000    0.000066406464612    0.000002652284593    1     benchmark2d_omp_cpu\n",
    "!\n",
    "!     400000000     0.822    2000    0.000033204873034    0.000001326215056    1     benchmark2d_omp_gpu                 !     400000000     0.430    2000    0.000033204873034    0.000001326215056    1     benchmark2d_docon                   !    1600000000     3.203    2000    0.000016602891264    0.000000663109006    1     benchmark2d_omp_gpu            \n",
    "!    1600000000     1.919    2000    0.000016602891264    0.000000663109006    1     benchmark2d_docon   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c6d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lmod is automatically replacing \"gcc/11.3.0\" with \"nvhpc-no-mpi/22.5\".\n",
      "\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.12.2     2) netcdf/4.9.0     3) openmpi/4.1.4\n",
      "\n",
      "rm: cannot remove ‘./gpu_offload_test2d’: No such file or directory\n",
      "      size      time(s) iterations initial_sum     final_sum        omp_nthreads    subroutine\n",
      "     100000000     0.563    2000    0.000066406464612    0.000002652284593    1     benchmark2d_omp_gpu                               \n",
      "     100000000     0.440    2000    0.000066406464612    0.000002652284593    1     benchmark2d_docon                                 \n"
     ]
    }
   ],
   "source": [
    "!source envs.gpubox;\\rm ./gpu_offload_test2d; nvfortran -O2 -mp=gpu -stdpar gpu_offload_test2d.f90 -o gpu_offload_test2d;./gpu_offload_test2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
