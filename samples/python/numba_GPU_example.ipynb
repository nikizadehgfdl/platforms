{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "871090bd-7073-41be-880d-a5737204f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nikizadeh-nzcacobaltgpuoffloadcopyp3-00012-1-0001\n"
     ]
    }
   ],
   "source": [
    "!hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc3cd6e8-4cc3-47a8-83bb-853b0b35639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 20 16:32:28 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB            Off| 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   32C    P0               38W / 300W|   1074MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1022      C   ...niconda3/envs/plattorch2/bin/python     1072MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faac0a9f-bade-4498-bb38-52b02481033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /contrib/Niki.Zadeh/opt/miniconda3\n",
      "platforms                /contrib/Niki.Zadeh/opt/miniconda3/envs/platforms\n",
      "plattorch                /contrib/Niki.Zadeh/opt/miniconda3/envs/plattorch\n",
      "plattorch2            *  /contrib/Niki.Zadeh/opt/miniconda3/envs/plattorch2\n",
      "                         /home/Niki.Zadeh/pw/.miniconda\n",
      "                         /home/Niki.Zadeh/source\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5910077-060b-4dff-ac74-8c07d13444b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bc57d98-a75a-40fa-b709-fe4faff16e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccdc4f64-698a-4d6a-b75e-866d51291a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "c = np.arange(4*4).reshape((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9ec7b50-71a4-4a98-a60c-f00fc35b4598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.47 µs ± 15.1 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.add(b, c)   # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4f21b2b-ac5a-403a-a1c0-54e5f9f55401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "@vectorize(['int64(int64, int64)'], target='cuda') # Type signature and target are required for the GPU\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebe54817-3a98-42e1-85a4-a2800843560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/Niki.Zadeh/opt/miniconda3/envs/plattorch2/lib/python3.9/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27 ms ± 3.73 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit add_ufunc(b, c) # Numba on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70a9da5d-6ffa-4ee0-837d-cae47aae61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.stats # for definition of gaussian distribution, so we can compare CPU to GPU time\n",
    "#norm_pdf = scipy.stats.norm\n",
    "#%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9a7a311-a334-4a93-a6b6-42a370d93560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "\n",
    "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.  Numba will inline it at compile time.\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)\n",
    "\n",
    "\n",
    "@vectorize\n",
    "def cpu_gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e8fcfef-edc1-4ad2-9fc4-110823e0dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/contrib/Niki.Zadeh/opt/miniconda3/envs/plattorch2/lib/python3.9/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02808081], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Evaluate the Gaussian a million times!\n",
    "x = np.random.uniform(-3, 3, size=1000000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)\n",
    "\n",
    "# Quick test on a single element just to make sure it works\n",
    "gaussian_pdf(x[0], 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c3ea989-e79d-42f9-850b-bd896f520491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.44 ms ± 72 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "673a29a8-0b80-40f2-8524-2e8739c9747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.6 ms ± 169 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cpu_gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5c914d6-edab-45c5-824a-b0351a4057f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def polar_to_cartesian(rho, theta):\n",
    "    x = rho * math.cos(theta)\n",
    "    y = rho * math.sin(theta)\n",
    "    return x, y\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32)'], target='cuda')\n",
    "def polar_distance(rho1, theta1, rho2, theta2):\n",
    "    x1, y1 = polar_to_cartesian(rho1, theta1) # We can use device functions inside our GPU ufuncs\n",
    "    x2, y2 = polar_to_cartesian(rho2, theta2)\n",
    "    \n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb8d36ee-62e6-4e1c-8e4c-cc44c0f2a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "rho1 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta1 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)\n",
    "rho2 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta2 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb5e4c83-6dc9-4671-b24b-e34970547d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.69 ms ± 886 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit polar_distance(rho1, theta1, rho2, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e37fdba5-c890-4c37-bbf3-216454342c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_to_cartesian_np(rho, theta):\n",
    "    x = rho * np.cos(theta)\n",
    "    y = rho * np.sin(theta)\n",
    "    return x, y\n",
    "\n",
    "def polar_distance_np(rho1, theta1, rho2, theta2):\n",
    "    x1, y1 = polar_to_cartesian_np(rho1, theta1) # We can use device functions inside our GPU ufuncs\n",
    "    x2, y2 = polar_to_cartesian_np(rho2, theta2)\n",
    "    \n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0de2c3f1-a5c0-40a3-9b83-f1049b5c3fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.7 ms ± 589 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit polar_distance_np(rho1, theta1, rho2, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5574818e-5ffc-4b57-9610-7450842e0508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:                  25.569903383031487  result=  200000000.0\n",
      "numpy nonvecable:      43.80844003899256  result=  200000000.0\n",
      "numba jit nonvecable: 0.24698784801876172  result=  200000000.0\n",
      "numba jit:            0.24826496798777953  result=  200000000.0\n"
     ]
    }
   ],
   "source": [
    "from numba import jit, cuda\n",
    "import numpy as np\n",
    "# to measure exec time\n",
    "from timeit import default_timer as timer \n",
    "\n",
    "# normal function to run on cpu\n",
    "def func(a):\n",
    "    for i in range(100000000):\n",
    "        a[i]+= 1\n",
    "    return a\n",
    "\n",
    "@jit \n",
    "def func_numba(a):\n",
    "    for i in range(100000000):\n",
    "        a[i]+= 1\n",
    "    return a\n",
    "\n",
    "@jit \n",
    "def func_numba_nonvecable(a):\n",
    "    asum=0.0\n",
    "    for i in range(100000000):\n",
    "        a[i]+= 1\n",
    "        asum += a[i]\n",
    "    return asum\n",
    "\n",
    "def func_nonvecable(a):\n",
    "    asum=0.0\n",
    "    for i in range(100000000):\n",
    "        a[i]+= 1\n",
    "        asum += a[i]\n",
    "    return asum\n",
    "\n",
    "\n",
    "\n",
    "n = 100000000\n",
    "a = np.ones(n, dtype = np.float64)\n",
    "start = timer()\n",
    "b=func(a)\n",
    "print(\"numpy:                 \", timer()-start, \" result= \",b.sum()) \n",
    "\n",
    "a = np.ones(n, dtype = np.float64)\n",
    "start = timer()\n",
    "b=func_nonvecable(a)\n",
    "print(\"numpy nonvecable:     \", timer()-start, \" result= \",b)\n",
    "\n",
    "a = np.ones(n, dtype = np.float64)\n",
    "start = timer()\n",
    "b=func_numba_nonvecable(a)\n",
    "print(\"numba jit nonvecable:\", timer()-start, \" result= \",b)\n",
    "\n",
    "a = np.ones(n, dtype = np.float64)\n",
    "start = timer()\n",
    "b=func_numba(a)\n",
    "print(\"numba jit:           \", timer()-start, \" result= \",b.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a12ab502-66dc-4163-9a93-89c280cd7a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba jit cuda:       0.529195251991041  result=  200000000.0\n",
      "numba jit     :       0.352728470985312  result=  200000000.0\n",
      "numpy         :       0.08615502197062597  result=  200000000.0\n"
     ]
    }
   ],
   "source": [
    "from numba import vectorize\n",
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def func_add1_numba_cuda(a):\n",
    "    a += 1\n",
    "    return a\n",
    "\n",
    "\n",
    "@jit\n",
    "def func_add1_numba(a):\n",
    "    a += 1\n",
    "    return a\n",
    "\n",
    "def func_add1(a):\n",
    "    a += 1\n",
    "    return a\n",
    "\n",
    "a = np.ones(n).astype(np.float32)\n",
    "start = timer()\n",
    "b=func_add1_numba_cuda(a)\n",
    "print(\"numba jit cuda:      \", timer()-start, \" result= \",b.sum())\n",
    "\n",
    "a = np.ones(n).astype(np.float32)\n",
    "start = timer()\n",
    "b=func_add1_numba(a)\n",
    "print(\"numba jit     :      \", timer()-start, \" result= \",b.sum())\n",
    "\n",
    "a = np.ones(n).astype(np.float32)\n",
    "start = timer()\n",
    "b=func_add1(a)\n",
    "print(\"numpy         :      \", timer()-start, \" result= \",b.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce0a56-5353-42ab-9483-adb80e3013a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
